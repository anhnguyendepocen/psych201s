---
title: "ch3_part2"
author: "mht"
date: "June 23, 2016"
output: html_document
---

### 3.4 Prior and posterior prediction

** The binomial posterior is wonky because of bugs with binomial in webppl.**
** fixed in commit fb740b4 **

```{r}
firstModelWithPredictives <- '
// Unpack data
var k = observed_data["k"][0] // number of heads
var n = observed_data["n"][0] // number of flips
var model = function() {
   var p = uniform( {a:0, b:1} )

   observe({
      data : k,           // Observed k number of Heads
      link: Binomial( {p : p, n: n }) // assuming a Binomial distribution
   })

   var posteriorPredictive = sample(Binomial({p : p, n: n}))
   var prior = uniform({ a: 0, b: 1});
   var priorPredictive = sample(Binomial({p : prior, n: n}))
   return {prior: prior, 
           priorPredictive : priorPredictive,
           posterior : p,
           posteriorPredictive : posteriorPredictive
          };
}
'
```

```{r}
observed_data <- list(k = 1, n = 15)
results <- runModel32(firstModelWithPredictives, observed_data) 

head(results) ## what does the data look like

results %>%
  select(prior, posterior) %>% # grab only prior and posterior columns
  gather(distribution, value) %>% # flatten them into a key and value column see http://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf for details on select/gather
  ggplot(aes(x = value, fill = distribution)) +
  geom_histogram()



  geom_density(alpha = .5)

results %>%
  select(priorPredictive, posteriorPredictive) %>%
  gather(distribution, value) %>%
  ggplot(aes(x = value, group = distribution, color = distribution)) +
  geom_bar(alpha = .5, position = "dodge")
```

# 3.4.1


# 3.4.2

```{r}
newPriorModel <- '
// Unpack data
var k = observed_data["k"] // number of heads
var n = observed_data["n"] // number of flips

var model = function() {
   var p = beta({a : ..., b : ...})  // TRY NEW PRIOR HERE
   
   observe({
      data : k,           // Observed k number of Heads
      link: Binomial( {p : p, n: n }) // assuming a Binomial distribution
   }) 

   var posteriorPredictive = sample(Binomial({p : p, n: n}))
   var prior = uniform({ a: 0, b: 1});
   var priorPredictive = sample(Binomial({p : prior, n: n}))
   return {prior: prior, 
           priorPredictive : priorPredictive,
           posterior : p,
           posteriorPredictive : posteriorPredictive};
}
'
```

# 3.4.3

```{r}
newPredictiveModel <- '
// Unpack data
var k = observed_data["k"] 
var n = observed_data["n"] 
var n_prime = ... // ENTER NEW N_PRIME FOR PREDICTIVES

var model = function() {
   var p = beta({a : 1, b : 1})  
   
   observe({
      data : k,          
      link: Binomial( {p : p, n: n }) 
   }) 

   // AFTER LEARNING ABOUT P, WE CAN MAKE PREDICTIONS FOR N_PRIME
   var posteriorPredictive = sample(Binomial({p : p, n: n_prime }))
   var prior = uniform({ a: 0, b: 1});
   var priorPredictive = sample(Binomial({p : prior, n: n}))
   return {prior: prior, 
           priorPredictive : priorPredictive,
           posterior : p,
           posteriorPredictive : posteriorPredictive};
}
'
```

# 3.4.4

```{r}
TrompetterModel <- '
// Original data
var k = 24
var n = 121

// Uncomment to try your own data!
// var k = observed_data["k"] 
// var n = observed_data["n"] 

var model = function() {
   var p = beta({a : 1, b : 1})  
   
   observe({
      data : k,          
      link: Binomial( {p : p, n: n }) 
   }) 

   var posteriorPredictive = sample(Binomial({p : p, n: n}))
   var prior = uniform({ a: 0, b: 1});
   var priorPredictive = sample(Binomial({p : prior, n: n}))
   return {prior: prior, 
           priorPredictive : priorPredictive,
           posterior : p,
           posteriorPredictive : posteriorPredictive};
}
'
```

### 3.5 Posterior Prediction

** Rejection sampling fails here **

```{r}
commonRateModelWithPredictives <- '
// Unpack data
var k1 = observed_data["k1"]
var k2 = observed_data["k2"]
var n1 = observed_data["n1"]
var n2 = observed_data["n2"]

var model = function() {
  // Sample rate from uniform distribution
  var p = uniform( {a:0, b:1} )
  
  // account for first data point using p
  observe({
    data : k1,           // Observed k number of Heads
    link: Binomial( {p : p, n: n1 }) // assuming a Binomial distribution
  }) 

  // account for second data point also using p
  observe({
    data : k2,           // Observed k number of Heads
    link: Binomial( {p : p, n: n2 }) // assuming a Binomial distribution
  }) 

  return {p : p,
          };
}
'
```

```{r}
observed_data <- list(k1 = 0, n1 = 10, k2 = 10, n2 = 10)
res <- runModel(commonRateModelWithPredictives, observed_data, numSamples = 1)
```


# 3.5.1

# 3.5.2

# 3.5.3

### 3.6 Joint distributions

```{r}
# k: List of m success counts
Survey <- '
// Unpack data
var nmax = observed_data["nmax"]
var k = observed_data["k"]
var probs = repeat(nmax, function() {return 1/nmax;});
var vals = _.range(1, nmax + 1)

// Inferring a Rate
var model = function() {
  var n = categorical( {ps: probs, vs: vals} );
  var p = beta({a: 1, b: 1})
  observe({
    data : k,           // Observed k number of Heads
    link: Binomial( {p : p, n: n }) // assuming a Binomial distribution
  })
  return {n: n, p: p}
}
'
```

```{r}
observed_data <- list(k = c(16, 18, 22, 25, 27), nmax = 500)
output <- runModel(Survey, observed_data, numSamples = 100000, method = "incrementalMH") 
ggs_pairs(output)
```

# 3.6.1

# 3.6.2

# 3.6.3

```{r}
observed_data <- list(k = c(16, 18, 22, 25, 28), nmax = 500)
output <- runModel(Survey, observed_data, numSamples = 100000, method = "incrementalMH") 
ggs_pairs(output)
```
