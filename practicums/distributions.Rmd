---
title: 'Psych 201s: Randomness in R'
author: "mht"
date: "May 5, 2016"
output: html_document
---
Load some packages
```{r}
library(tidyr)
library(dplyr)
library(ggplot2)
```


A fundamental concept in probability and statistics is that of a probability distribution.
There are different kinds of distributions, called "families", corresponding to different "random processes". 

We'll consider a few here. 
First, we'll explore the distributions using R. 

# Bernoulli distribution

The simplest probability distribution results from the random process of flipping a coin.
You can think of this as a 2-alternative forced choice task.

There are 4 functions in R you can use to access probility distributions.

We're going to be through them through visualization using the Bernoulli and the Binomial distributions.

### Samples

My favorite function is the random sampling function. 
syntax: `rbinom(size = number_of_trials, prob = probability_of_success, n = number_of_participants)`

A Bernoulli is a single trial experiment, a single flip of a coin: `size = 1`
If `prob = 0.5`, we are dealing with a fair coin (e.g., if participants are guessing at random).

An outcome is a success 1 (heads) or a failure 0 (tails).

Here is one trial for one participant.
```{r}
rbinom(size = 1, prob = 0.5, n = 1) # run this a couple of times
```

Simulate 100 participants, 1 trial each

```{r}
rbinom(size = 1, prob = 0.5, n = 100)
```

Kind of messy just looking at numbers. Let's pass it qplot.

```{r}
rbinom(size=1, prob=0.5, n = 100) %>%
  qplot()
# qplot is smart and if you give it a list of numbers, it will make you a histogram automagically
```

Note: The above code is the same as `qplot(rbinom(size = 1, prob = 0.5, n = 100)) `

In some languages, to get a sample from the Bernoulli distribution, you write `flip(prob = 0.5)` [because a sample from the bernoulli distribution is the same as flipping a coin].

# Binomial distribution

The Bernoulli distrubition (above) is very intimately related to the Binomial distribution (the Bernoulli distribution is a special case of the Binomial distribution). In fact, we've already been calling the Binomial distribution sampling function.

The binomial distribution is the result of flipping the same coin multiple times, and counting up how many heads you got.
Or, in our psychology experiment analogy, have multiple trials for each participant. (In this case, the trials are same, or perhaps you can imagine they are part of the same experimental condition.)

Single participant, 3 trials.

```{r}
rbinom(size = 3, prob = 0.5, n = 1) # run this a couple of times
```

What is the relationship of the above code, to the code below?

```{r}
rbinom(size = 1, prob = 0.5, n = 3) # run this a couple of times
```

What if we flip 100 coins, and each of them we flip 5 times?
(or, 100 participants, 5 trials each)

```{r}
rbinom(size = 5, prob = 0.5, n = 100) %>%
  qplot()
```

What is the X axis?


What are the bounds of the X-axis (max value, min value), and why are they what they are?

What do the heights of the bars represent?

Is 2 more probable than 3?

Try running 1000 participants.

What about now?

10000 participants!


Simulate a distribution of outcomes of 10000 participants with 20 trials / participant, with a true probability of success of 0.5

[If you're not comfortable imagining 10000 participants, you can substitute in your head participants with *experiments* and trials with *participants* (and it will be a single trial experiment). So this would be 10000 experiments of 20 participants doing a single trial experiment.].

```{r}
rbinom(size = ..., prob = ..., n = ...) %>%
  qplot()
```

What if the true probability of success is 0.75?

What can you read off this distribution? [Using either interpretation I provided above.]

Put in numbers that seem realistic for the types of experiments you run. (e.g. 20 participants, 3 trials each), and look at the distribution.

```{r}
rbinom(size = ..., prob = ..., n = ...) %>%
  qplot()
```

In all honesty, to think about distributions in R, I use the rbinom function (or `rnorm`, `rbeta`, `runif`, ...) 98% of the time.

There are other functions in R to help you think about distributions.

### Probability density

dbinom gives you the probability of a certain outcome (technically, this is called the *probability density*)
syntax: `dbinom(size = number_of_trials, prob = probability_of_success, x = outcome)` 
[also see ?dbinom]


We'll start back with the single trial, single participant setup.

```{r density}
dbinom(size = 1, prob = 0.5, x = 0)
```

Run this multiple times. Do you get different answers? Why or why not?

```{r}
# you can also supply a vector of outcomes
dbinom(size = 1, prob = 0.5, x = c(0,1))
```

What happens if you change the `probability_of_success` to 0.8?

What happens if you set the outcome to a number other than 0 or 1?

What happens if you set the `probability_of_success` to a number less than 0 or greater than 1?

Let's try the binomial with 5 flips (e.g. 5 trials per participant)

What's the probabilty of 2? of 3?
```{r}
dbinom(size = 5, prob = 0.5, x = 2)
```

Here, we get an exact answer (unlike before when we were looking at the results of rbinom in a histogram).

We can try for every possible outcome. 
```{r}
dbinom(size = 5, prob = 0.5, x = c(0,1,2,3,4,5))
```

Let's save the output, and visualize it!

```{r}
probabilities <- dbinom(size = 5, prob = 0.5, x = c(0,1,2,3,4,5))

binomial_density <- data.frame(
          values = c(0,1,2,3,4,5),
           probs = probabilities
          )

binomial_density

ggplot(binomial_density,
       aes(x = values, y = probs))+
  geom_bar(stat='identity', position=position_dodge())
```

Ooh, ahh. Do you understand why this is perfectly symmetric while the one we made before was jaggedy?

Try changing the `prob` to different numbers to see how this changes.

### Cumulative probability

What we just looked at was the probability associated with different outcomes.
Sometimes, we are interested in the *cumulative* probability.
This is the probabilty of a given outcome, or outcomes less than that.
(for example, the probability that participants got 2 or fewer trials correct, out of 5)


Let's jump straight to the visualization because that's the most fun.
(Feel free to execute all the intermediary steps, and try it with different parameters).

```{r}
probabilities <- pbinom(size = 5, prob = 0.5, q = c(0,1,2,3,4,5))

binomial_cumulative <- data.frame(
          values = c(0,1,2,3,4,5),
           probs = probabilities
          )

binomial_cumulative

ggplot(binomial_cumulative, 
       aes(x = values, y = probs))+
  geom_bar(stat='identity', position=position_dodge())
```

Why is the probability of 4 in this graph greater than the probabilty of 4 in the density graph (the one from before)?

### Quantile function

The quantile function is arguably the weirdest of the functions, and I don't fully understand it's utility. Certaintly in these examples, it's quite esoteric. But maybe you'll find a use for it at some point in your career.

qbinom is the opposite of pbinom.

pbinom: outcome -> cumulative_probability
qbinom: cumulative_probability -> outcome

It's not exactly true but it's close. 
Actually, qbinom will give you the max(outcome).

syntax: `qbinom(size = number_of_trials, prob = probability_of_success, p = cumulative_probabilities)` 

```{r quantile}

cumulative_probabilities <- c(0, 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1)

outcomes <- qbinom(size = 5, prob = 0.5, p = cumulative_probabilities)

binomial_quantiles <- data.frame(
          probs = cumulative_probabilities,
           values = outcomes
          )

ggplot(binomial_quantiles, 
       aes(x = probs, y = values))+
  geom_bar(stat='identity', position=position_dodge())

```

This is definitely the weirest plot of the 4. 
I could imagine using something like this to draw confidence intervals.
Let's try it:

```{r quantile}

cumulative_probabilities <- c(0.025, 0.975) # 95 % quantiles

outcomes <- qbinom(size = 5, prob = 0.5, p = cumulative_probabilities)

binomial_quantiles <- data.frame(
          probs = cumulative_probabilities,
           values = outcomes
          )

ggplot(binomial_quantiles, 
       aes(x = probs, y = values))+
  geom_bar(stat='identity', position=position_dodge())

```

That's extremely boring. What if we change the number of coin flips (size) from 5 to 100?

What does that tell us?


So far, we've look at only the outcome of flipping a coin (a bernoulli) and of flipping a coin multiple times (a binomial).

Let's look at Gaussian distributions, now.


# The Gaussian distribution



