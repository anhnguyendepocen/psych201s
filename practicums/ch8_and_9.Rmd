---
title: "ch8"
author: "mht"
date: "October 30, 2014"
output: html_document
---
# Chapter 8: Comparing Gaussian Means

When we use the one-sample t-test, we assume that the data follow a Gaussian distribution with unknown mean mu and unknown variance sigma^2. This is a natural assumption for a within-subjects experimental design, like that undertaken by Dr Smith. The data consist of one sample of standardized difference scores (i.e., “winter scores − summer scores”). The null hypothesis states that the mean of the difference scores is equal to zero, that is, H0 : mu = 0. The alternative hypothesis states that the mean is not equal to zero, that is, H1: mu != 0.

## 8.1 One-sample comparison

```{r libraries, fig.width=10, fig.height=4, echo=FALSE}
library(rwebppl)
library(dplyr)
library(tidyr)
library(ggplot2)
library(polspline)


getwd()
setwd("~/Repos/psych201s/practicums/")

```


```{r 8.1.1}
model<- 
'// One-Sample Comparison of Means

var discreteCauchy = Infer({method: "enumerate"}, function(){
  var bins = utils.range(-5, 5, .05);
  var params = {location: 0, scale : 1};
  var probs = map(function(b){ Math.exp(Cauchy(params).score(b)) } , bins);
  return bins[discrete(probs)];
});

var discreteGaussian = Infer({method: "enumerate"}, function(){
  var bins = utils.range(-5, 5, .05);
  var params = {mu: 0, sigma : 1};
  var probs = map(function(b){ Math.exp(Gaussian(params).score(b)) } , bins);
  return bins[discrete(probs)];
});

var model = function(){
  var nullModel = flip()
  var delta = nullModel ? 0 : sample(discreteCauchy);
  // var delta = nullModel ? 0 : sample(discreteGaussian);
  
  var sigma = Math.abs(sample(discreteCauchy));
  var mu = delta*sigma;
  observe({
    data: data,
    link: Gaussian({mu:mu, sigma: sigma})
  })
  return {
    nullModel: nullModel,
    delta: delta,
    sigma: sigma
  }
}'



# Read data Dr. Smith
Winter <- c(-0.05,0.41,0.17,-0.13,0.00,-0.05,0.00,0.17,0.29,0.04,0.21,0.08,0.37,0.17,0.08,-0.04,-0.04,0.04,-0.13,-0.12,0.04,0.21,0.17,
       0.17,0.17,0.33,0.04,0.04,0.04,0.00,0.21,0.13,0.25,-0.05,0.29,0.42,-0.05,0.12,0.04,0.25,0.12)
 
Summer <- c(0.00,0.38,-0.12,0.12,0.25,0.12,0.13,0.37,0.00,0.50,0.00,0.00,-0.13,-0.37,-0.25,-0.12,0.50,0.25,0.13,0.25,0.25,0.38,0.25,0.12,
      0.00,0.00,0.00,0.00,0.25,0.13,-0.25,-0.38,-0.13,-0.25,0.00,0.00,-0.12,0.25,0.00,0.50,0.00)

x <- Winter-Summer # allowed because it is a within-subjects design
x <- x/sd(x)       # standardize

rs <- webppl(model,
       model_var= "model",
       inference_opts = list(method = "enumerate",
                             verbose = TRUE),
      packages = c("./utils"),
      data = x,
      data_var = "data"
)

ggplot(rs %>% group_by(delta) %>% summarize(prob = sum(prob)), 
       aes(x = delta, y = prob))+
  geom_line()

ggplot(rs %>% group_by(sigma) %>% summarize(prob = sum(prob)), 
       aes(x = sigma, y = prob))+
  geom_line()

ggplot(rs %>% group_by(nullModel) %>% summarize(prob = sum(prob)), 
       aes(x = nullModel, y = prob))+
  geom_bar(stat = 'identity')
```

Compute Bayes Factor using the Savage-Dickey method

```{r}
nullProbsTable <- rs %>% 
  group_by(nullModel) %>% 
  summarize(prob = sum(prob)) 

BF01 = nullProbsTable[2,2]/ nullProbsTable[1,2] 

print(paste("The null hypothesis is", BF01, "times more likely than the alternative hypothesis."))
```

The Bayes factor between H0 and H1 is `r BF01`

### Exercise 8.1.3 

We also assumed a Cauchy prior distribution on effect size delta. Other choices are possible and reasonable. One such choice is the standard Gaussian distribution. Do you think this prior will lead to substantially different conclusions? Why or why not? Convince yourself by implementing the standard Gaussian prior and studying the result.

Hint: Remember to switch the priorProbability to use the gaussian as well 

## 8.2 Order-restricted one-sample comparison

Order-restricted hypothesis is also known as one-sided hypothesis.
```{r 8.2}
model<- 
'
var halfDiscreteCauchy = Infer({method: "enumerate"}, function(){
  var bins = utils.range(-10.001, 0.0, .05);
  var params = {location: 0, scale : 1};
  var probs = map(function(b){ Math.exp(Cauchy(params).score(b)) } , bins);
  return bins[discrete(probs)];
});

var model = function(){
  var nullModel = flip()
  var delta = nullModel ? 0 : sample(halfDiscreteCauchy);

  var sigma = -1 * sample(halfDiscreteCauchy);
  var mu = delta*sigma;

  observe({
    data: data,
    link: Gaussian({mu:mu, sigma: sigma})
  })

  return {
    nullModel: nullModel,
    delta: delta,
    sigma: sigma
  }
}'

# Read data Dr. Smith
Winter <- c(-0.05,0.41,0.17,-0.13,0.00,-0.05,0.00,0.17,0.29,0.04,0.21,0.08,0.37,0.17,0.08,-0.04,-0.04,0.04,-0.13,-0.12,0.04,0.21,0.17,
       0.17,0.17,0.33,0.04,0.04,0.04,0.00,0.21,0.13,0.25,-0.05,0.29,0.42,-0.05,0.12,0.04,0.25,0.12)
 
Summer <- c(0.00,0.38,-0.12,0.12,0.25,0.12,0.13,0.37,0.00,0.50,0.00,0.00,-0.13,-0.37,-0.25,-0.12,0.50,0.25,0.13,0.25,0.25,0.38,0.25,0.12,
      0.00,0.00,0.00,0.00,0.25,0.13,-0.25,-0.38,-0.13,-0.25,0.00,0.00,-0.12,0.25,0.00,0.50,0.00)

x <- Winter-Summer # allowed because it is a within-subjects design
x <- x/sd(x)       # standardize

rs <- webppl(model,
       model_var= "model",
       inference_opts = list(method="enumerate",
                          verbose = TRUE),
      packages = c("./utils"),
      data = x,
      data_var = "data"
)

ggplot(rs %>% group_by(delta) %>% summarize(prob = sum(prob)), 
       aes(x = delta, y = prob))+
  geom_line()

ggplot(rs %>% group_by(sigma) %>% summarize(prob = sum(prob)), 
       aes(x = sigma, y = prob))+
  geom_line()

ggplot(rs %>% group_by(nullModel) %>% summarize(prob = sum(prob)), 
       aes(x = nullModel, y = prob))+
  geom_bar(stat = 'identity')

```

Compute Bayes Factor using the Savage-Dickey method

```{r}
nullProbsTable <- rs %>% 
  group_by(nullModel) %>% 
  summarize(prob = sum(prob)) 

BF01 = nullProbsTable[2,2]/ nullProbsTable[1,2] 

print(paste("The null hypothesis is", BF01, "times more likely than the alternative hypothesis."))
```

### Exercise 8.2.2

In this example, it matters whether the alternative hypothesis is unrestricted, order-restricted to negative values for delta, or order-restricted to positive values for delta. Why is this perfectly reasonable? Can you think of a situation where the three versions of the alternative hypothesis yield exactly the same Bayes factor?

# 8.3 Two sample

```{r 8.3,fig.width=10, fig.height=4, echo=FALSE}
twoSampleModel <- 
'// One-Sample Comparison of Means
console.log("enumerating... This may take a couple minutes.")
var positiveDiscreteCauchy = Infer({method: "enumerate"}, function(){
  var bins = utils.range(0.001, 3, .1);
  var params = {location: 0, scale : 1};
  var probs = map(function(b){ Math.exp(Cauchy(params).score(b)) } , bins);
  return bins[discrete(probs)];
});

var discreteCauchy = Infer({method: "enumerate"}, function(){
  var bins = utils.range(-3, 3, .1);
  var params = {location: 0, scale : 1};
  var probs = map(function(b){ Math.exp(Cauchy(params).score(b)) } , bins);
  return bins[discrete(probs)];
});

var model = function(){
  var nullModel = flip()

  // standardized effect size
  var delta = nullModel ? 0 : sample(discreteCauchy);

  // mean of means
  var mu = sample(discreteCauchy);

  // standard deviation
  var sigma = Math.abs(sample(positiveDiscreteCauchy));

  // difference between the means
  var alpha = delta*sigma;

  observe({
    data: data.x,
    link: Gaussian({mu: mu + alpha/2, sigma: sigma})
  })

  observe({
    data: data.y,
    link: Gaussian({mu: mu - alpha/2, sigma: sigma})
  })

  return {
    nullModel : nullModel,
    delta: delta,
    mu: mu,
    sigma: sigma
  }
}'
# Read data Dr. Smith
x <- c(70,80,79,83,77,75,84,78,75,75,78,82,74,81,72,70,75,72,76,77)

y <- c(56,80,63,62,67,71,68,76,79,67,76,74,67,70,62,65,72,72,69,71)

# Rescale
y <- (y - mean(x))/sd(x)
x <- (x - mean(x))/sd(x)

observed_data = list(x = x, y = y)

rs <- webppl(twoSampleModel,
       model_var= "model",
       inference_opts = list(method = "enumerate",
                             verbose = TRUE),
      packages = c("./utils"),
      data = observed_data,
      data_var = "data"
)

ggplot(rs %>% group_by(delta) %>% summarize(prob = sum(prob)), 
       aes(x = delta, y = prob))+
  geom_line()

ggplot(rs %>% group_by(mu) %>% summarize(prob = sum(prob)), 
       aes(x = mu, y = prob))+
  geom_line()

ggplot(rs %>% group_by(sigma) %>% summarize(prob = sum(prob)), 
       aes(x = sigma, y = prob))+
  geom_line()

ggplot(rs %>% group_by(nullModel) %>% summarize(prob = sum(prob)), 
       aes(x = nullModel, y = prob))+
  geom_bar(stat = 'identity')
```

```{r}
nullProbsTable <- rs %>% 
  group_by(nullModel) %>% 
  summarize(prob = sum(prob)) 

BF01 = nullProbsTable[2,2]/ nullProbsTable[1,2] 

print(paste("The null hypothesis is", BF01, "times more likely than the alternative hypothesis."))

print(paste("In order words, the alternative hypothesis is", 1/BF01, "times more likely than the null hypothesis."))

```

## Exercise 8.3.1 

The two-sample comparison of means outlined above assumes that the two groups have equal variance. How can you extend the model when this assumption is not reasonable?

### 9.1: Equality of proportions

```{r 9.1}
model <- '
console.log("enumerating... may take a few minutes")
var discreteBeta = Infer({method: "enumerate"}, function(){
  var bins = utils.range(0, 1, .01);
  var params = {a: 1, b: 1};
  var probs = map(function(b){ Math.exp(Beta(params).score(b)) } , bins);
  return bins[discrete(probs)];
});

var model = function(){
  var nullModel = flip();
  var commonTheta = nullModel ? sample(discreteBeta) : null;
  var theta1 = nullModel ? commonTheta : sample(discreteBeta);
  var theta2 = nullModel ? commonTheta : sample(discreteBeta);

  observe({
    data: data.s1,
    link: Binomial({n: data.n1[0], p: theta1})
  })

  observe({
    data: data.s2,
    link: Binomial({n: data.n2[0], p: theta2})
  })

  //var theta1_prior = beta(1,1);
  //var theta2_prior = beta(1,1);

  return {
    nullModel: nullModel,
    delta: theta1 - theta2,
    //delta_prior: theta1_prior - theta2_prior
  }
}
'

s1 <- 424
s2 <- 5416
n1 <- 777
n2 <- 9072
observed_data = list(s1 = s1,
                     s2 = s2,
                     n1 = n1,
                     n2 = n2)

# two-sided p-value = 0.005848:
prop.test(c(s1,s2), c(n1,n2), alternative = c("two.sided")) 

# Analytical Bayes factor:
log.BF01 <- lchoose(n1,s1) + lchoose(n2,s2) + 
  log(n1+1) + log(n2+1) - 
  lchoose((n1+n2),(s1+s2)) - 
  log(n1+n2+1)

BF01 <- exp(log.BF01)

rs <- webppl(model,
       model_var= "model",
       inference_opts = list(method = "enumerate",
                             verbose = TRUE),
      packages = c("./utils"),
      data = observed_data,
      data_var = "data"
)

ggplot(rs %>% group_by(delta) %>% summarize(prob = sum(prob)), 
       aes(x = delta, y = prob))+
  geom_line()

ggplot(rs %>% group_by(nullModel) %>% summarize(prob = sum(prob)), 
       aes(x = nullModel, y = prob))+
  geom_bar(stat = 'identity')
```

```{r}
nullProbsTable <- rs %>% 
  group_by(nullModel) %>% 
  summarize(prob = sum(prob)) 

BF01 = nullProbsTable[2,2]/ nullProbsTable[1,2] 

print(paste("The null hypothesis is", BF01, "times more likely than the alternative hypothesis."))

print(paste("In order words, the alternative hypothesis is", 1/BF01, "times more likely than the null hypothesis."))

# -- Exact solution: 2.223484

```


### Exercise 9.1.4

For the pledger data, a frequentist test for equality of proportions
indicates that p ~ 0.006. This tells us that when H0 is true (i.e., the proportions
of condom users are equal in the two groups), then the probability
is about 0.006 that we would encounter a result at least as extreme as the
one that was in fact observed. What conclusions would you draw based on
this information? Discuss the usefulness of the Bayes factor and the p-value
in answering the scientific question of whether pledgers are less likely than
non-pledgers to use a condom.