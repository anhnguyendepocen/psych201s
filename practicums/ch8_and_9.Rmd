---
title: "ch8"
author: "mht"
date: "October 30, 2014"
output: html_document
---

# Chapter 8: Comparing Gaussian Means

When we use the one-sample t-test, we assume that the data follow a Gaussian distribution with unknown mean μ and unknown variance σ2. This is a natural assumption for a within-subjects experimental design, like that undertaken by Dr Smith. The data consist of one sample of standardized difference scores (i.e., “winter scores − summer scores”). The null hypothesis states that the mean of the difference scores is equal to zero, that is, H0 : μ = 0. The alternative hypothesis states that themeanisnotequaltozero,thatis,H1 :μ̸=0.

## 8.1 One-sample comparison

```{r libraries, fig.width=10, fig.height=4, echo=FALSE}
library(rwebppl)
library(dplyr)
library(tidyr)
library(ggplot2)
library(polspline)


getwd()
setwd("~/Repos/psych201s/practicums/")

```


```{r 8.1.1}
model<- 
'// One-Sample Comparison of Means
var model = function(){
  var delta = sample(Cauchy({location: 0, scale: 1}));
  // var delta = sample(Gaussian({mu: 0, sigma: 1}));
  var sigma = Math.abs(sample(Cauchy({location: 0, scale: 1})));
  var mu = delta*sigma;
  observe({
    data: data,
    link: Gaussian({mu:mu, sigma: sigma})
  })
  return {
    delta: delta,
    sigma: sigma
  }
}'



# Read data Dr. Smith
Winter <- c(-0.05,0.41,0.17,-0.13,0.00,-0.05,0.00,0.17,0.29,0.04,0.21,0.08,0.37,0.17,0.08,-0.04,-0.04,0.04,-0.13,-0.12,0.04,0.21,0.17,
       0.17,0.17,0.33,0.04,0.04,0.04,0.00,0.21,0.13,0.25,-0.05,0.29,0.42,-0.05,0.12,0.04,0.25,0.12)
 
Summer <- c(0.00,0.38,-0.12,0.12,0.25,0.12,0.13,0.37,0.00,0.50,0.00,0.00,-0.13,-0.37,-0.25,-0.12,0.50,0.25,0.13,0.25,0.25,0.38,0.25,0.12,
      0.00,0.00,0.00,0.00,0.25,0.13,-0.25,-0.38,-0.13,-0.25,0.00,0.00,-0.12,0.25,0.00,0.50,0.00)

x <- Winter-Summer # allowed because it is a within-subjects design
x <- x/sd(x)       # standardize

numSamples = 15000
rs <- webppl(model,
       model_var= "model",
       inference_opts = list(method = "MCMC",
                             samples = numSamples,
                             burn = numSamples/2,
                             verbose = TRUE),
      packages = c("./utils"),
      output_format = "samples",
      data = x,
      data_var = "data"
)


rs.tidy <- rs %>% 
  gather(param, value)

ggplot(rs.tidy, aes(x = value))+
  geom_histogram()+
  facet_wrap(~param, scales = 'free')
```

Compute Bayes Factor using the Savage-Dickey method

```{r}
fit.posterior <- logspline(rs$delta)

# posterior density at critical value: delta = 0
posteriorProbability <- dlogspline(0, fit.posterior)

# prior density at critical value: delta = 0
priorProbability <- dcauchy(x=0, location = 0, scale = 1)
# priorProbability <- dnorm(x = 0)

# bayes factor 01: null vs. alternative
BF01 <- posteriorProbability/priorProbability

print(paste("The null hypothesis is", BF01, "times more likely than the alternative hypothesis."))
```

The Bayes factor between H0 and H1 is `r BF01`

### Exercise 8.1.3 

We also assumed a Cauchy prior distribution on effect size delta. Other choices are possible and reasonable. One such choice is the standard Gaussian distribution. Do you think this prior will lead to substantially different conclusions? Why or why not? Convince yourself by implementing the standard Gaussian prior and studying the result.


## 8.2 Order-restricted one-sample comparison

Order-restricted hypothesis is also known as one-sided hypothesis.
```{r 8.2}
model<- 
'
var model = function(){
  var delta = -1*Math.abs(sample(Cauchy({location: 0, scale: 1})));
  // var delta = Math.abs(sample(Cauchy({location: 0, scale: 1})));

  var sigma = Math.abs(sample(Cauchy({location: 0, scale: 1})));
  var mu = delta*sigma;
  observe({
    data: data,
    link: Gaussian({mu:mu, sigma: sigma})
  })
  return {
    delta: delta,
    sigma: sigma
  }
}'



# Read data Dr. Smith
Winter <- c(-0.05,0.41,0.17,-0.13,0.00,-0.05,0.00,0.17,0.29,0.04,0.21,0.08,0.37,0.17,0.08,-0.04,-0.04,0.04,-0.13,-0.12,0.04,0.21,0.17,
       0.17,0.17,0.33,0.04,0.04,0.04,0.00,0.21,0.13,0.25,-0.05,0.29,0.42,-0.05,0.12,0.04,0.25,0.12)
 
Summer <- c(0.00,0.38,-0.12,0.12,0.25,0.12,0.13,0.37,0.00,0.50,0.00,0.00,-0.13,-0.37,-0.25,-0.12,0.50,0.25,0.13,0.25,0.25,0.38,0.25,0.12,
      0.00,0.00,0.00,0.00,0.25,0.13,-0.25,-0.38,-0.13,-0.25,0.00,0.00,-0.12,0.25,0.00,0.50,0.00)

x <- Winter-Summer # allowed because it is a within-subjects design
x <- x/sd(x)       # standardize

numSamples = 10000
rs <- webppl(model,
       model_var= "model",
       inference_opts = list(method = "MCMC",
                             kernel = list(
                               HMC = list(
                                 steps = 5,
                                 stepSize = 0.01
                               )
                             ),
                             samples = numSamples,
                             burn = numSamples/2,
                             verbose = TRUE),
      packages = c("./utils"),
      output_format = "samples",
      data = x,
      data_var = "data"
)


rs.tidy <- rs %>% 
  gather(param, value)

ggplot(rs.tidy, aes(x = value))+
  geom_histogram()+
  facet_wrap(~param, scales = 'free')
```

Compute Bayes Factor using the Savage-Dickey method

```{r}
fit.posterior <- logspline(rs$delta)

# posterior density at critical value: delta = 0
posteriorProbability <- dlogspline(0, fit.posterior)

# prior density at critical value: delta = 0
priorProbability <- dcauchy(x=0, location = 0, scale = 1)

# bayes factor 01: null vs. alternative
BF01 <- posteriorProbability/priorProbability

print(paste("The null hypothesis is", BF01, "times more likely than the alternative hypothesis."))
```

### Exercise 8.2.1

For completeness, estimate the Bayes factor for the summer and
winter data between H0 : delta = 0 versus H3 : Cauchy 0, 1 I(0,∞,), involving the order-restricted alternative hypothesis that assumes the effect is positive.

### Exercise 8.2.2

In this example, it matters whether the alternative hypothesis is unrestricted, order-restricted to negative values for δ, or order-restricted to positive values for δ. Why is this perfectly reasonable? Can you think of a situation where the three versions of the alternative hypothesis yield exactly the same Bayes factor?

# 8.3 Two sample

```{r 8.3,fig.width=10, fig.height=4, echo=FALSE}
twoSampleModel <- 
'// One-Sample Comparison of Means
var model = function(){
  // standardized effect size
  var delta = sample(Cauchy({location: 0, scale: 1}));

  // mean of means
  var mu = sample(Cauchy({location: 0, scale: 1}));

  // standard deviation
  var sigma = Math.abs(sample(Cauchy({location: 0, scale: 1})));

  // difference between the means
  var alpha = delta*sigma;

  observe({
    data: data.x,
    link: Gaussian({mu: mu + alpha/2, sigma: sigma})
  })

  observe({
    data: data.y,
    link: Gaussian({mu: mu - alpha/2, sigma: sigma})
  })

  return {
    delta: delta,
    mu: mu,
    sigma: sigma
  }
}'
# Read data Dr. Smith
x <- c(70,80,79,83,77,75,84,78,75,75,78,82,74,81,72,70,75,72,76,77)

y <- c(56,80,63,62,67,71,68,76,79,67,76,74,67,70,62,65,72,72,69,71)

# Rescale
y <- (y - mean(x))/sd(x)
x <- (x - mean(x))/sd(x)

observed_data = list(x = x, y = y)
numSamples = 3000
rs <- webppl(twoSampleModel,
       model_var= "model",
       inference_opts = list(method = "MCMC",
                             kernel = list(
                               HMC = list(
                                 steps = 25,
                                 stepSize = 0.01
                               )
                             ),
                             samples = numSamples,
                             burn = numSamples/2,
                             verbose = TRUE),
      packages = c("./utils"),
      output_format = "samples",
      data = observed_data,
      data_var = "data"
)

rs.tidy <- rs %>% 
  gather(param, value)

ggplot(rs.tidy, aes(x = value))+
  geom_histogram()+
  facet_wrap(~param, scales = 'free')
```

Note: this requires estimates of probabilities way out in the tail of the distribution, which can be pretty unstable: try running it a few times to see if you get something reasonable

```{r}
fit.posterior <- logspline(rs$delta)

# posterior density at critical value: delta = 0
posteriorProbability <- dlogspline(0, fit.posterior)

# prior density at critical value: delta = 0
priorProbability <- dcauchy(x=0, location = 0, scale = 1)

# bayes factor 01: null vs. alternative
BF01 <- posteriorProbability/priorProbability

print(paste("The null hypothesis is", BF01, "times more likely than the alternative hypothesis."))

print(paste("In order words, the alternative hypothesis is", 1/BF01, "times more likely than the null hypothesis."))

```

## Exercise 8.3.1 

The two-sample comparison of means outlined above assumes that the two groups have equal variance. How can you extend the model when this assumption is not reasonable?

### 9.1: Equality of proportions

```{r 9.1}
model <- '
var model = function(){
  var theta1 = beta(1,1);
  var theta2 = beta(1,1);

  observe({
    data: data.s1,
    link: Binomial({n: data.n1[0], p: theta1})
  })

  observe({
    data: data.s2,
    link: Binomial({n: data.n2[0], p: theta2})
  })

  var theta1_prior = beta(1,1);
  var theta2_prior = beta(1,1);

  return {
    delta: theta1 - theta2,
    //delta_prior: theta1_prior - theta2_prior
  }
}
'

s1 <- 424
s2 <- 5416
n1 <- 777
n2 <- 9072
observed_data = list(s1 = s1,
                     s2 = s2,
                     n1 = n1,
                     n2 = n2)

# two-sided p-value = 0.005848:
prop.test(c(s1,s2), c(n1,n2), alternative = c("two.sided")) 

# Analytical Bayes factor:
log.BF01 <- lchoose(n1,s1) + lchoose(n2,s2) + 
  log(n1+1) + log(n2+1) - 
  lchoose((n1+n2),(s1+s2)) - 
  log(n1+n2+1)

BF01 <- exp(log.BF01)

numSamples = 3000
rs <- webppl(model,
       model_var= "model",
       inference_opts = list(method = "MCMC",
                             kernel = list(
                               HMC = list(
                                 steps = 5,
                                 stepSize = 0.01
                               )
                             ),
                             samples = numSamples,
                             burn = numSamples/2,
                             verbose = TRUE),
      packages = c("./utils"),
      output_format = "samples",
      data = observed_data,
      data_var = "data"
)

rs.tidy <- rs %>% 
  gather(param, value)

ggplot(rs.tidy, aes(x = value))+
  geom_histogram()+
  facet_wrap(~param, scales = 'free')

```

```{r}
# note the bounds
fit.prior     <- logspline(rs$delta_prior, lbound=-1, ubound=1) 
fit.posterior <- logspline(rs$delta, lbound=-1, ubound=1)

# 95% credible interval
x0 <- qlogspline(0.025,fit.posterior)
x1 <- qlogspline(0.975,fit.posterior)

# posterior density at critical value: delta = 0
posteriorProbability <- dlogspline(0, fit.posterior)

# prior density at critical value: delta = 0
priorProbability <- dlogspline(0, fit.prior)

# -- Exact solution: 2.223484

# bayes factor 10: alternative vs. null
BF10 <- 1/posteriorProbability/priorProbability

print(paste("The alternative hypothesis is", BF10, "times more likely than the null hypothesis."))
```


### Exercise 9.1.4

For the pledger data, a frequentist test for equality of proportions
indicates that p ≈ 0.006. This tells us that when H0 is true (i.e., the proportions
of condom users are equal in the two groups), then the probability
is about 0.006 that we would encounter a result at least as extreme as the
one that was in fact observed. What conclusions would you draw based on
this information? Discuss the usefulness of the Bayes factor and the p-value
in answering the scientific question of whether pledgers are less likely than
non-pledgers to use a condom.